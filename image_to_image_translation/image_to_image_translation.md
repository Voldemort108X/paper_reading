# Image to Image Translation

| Title | Motivation | Method | Conclusion | Application | Year | Limitation | Comment |
| - | - | - | - | - | - | - | - |
| Contrastive Learning for Unpaired Image-to-Image Translation [[Paper]](https://arxiv.org/pdf/2007.15651.pdf) | Maximize the mutual information of corresponding path in input and target using contrastive learning. | Multilayer, patchwise contrastive loss (patchNCE/external) + CycleGAN setting. | 1) Draw negatives within the image itself for contrastive loss. 2) Learns cross-domain similarity function without perceptual loss/L1 loss. 3) Enable one-sided translation without relying on cycle-consistency. 4) Enable single-image unpaired translation. | Unpaired image to image translation | 2020 | | PatchNCE takes average of (generated representation, postive representation, negative representation(other patches in the same image)). External takes average of (generated representation, postive representation, negative representation(other image patches in the dataset)). 
| DRIT++: Diverse Image-to-Image Translation via Disentangled Representations [[paper]](https://arxiv.org/pdf/1905.01270.pdf)
|Unsupervised Image-to-Image Translation Networks [[paper]](https://arxiv.org/pdf/1703.00848.pdf)